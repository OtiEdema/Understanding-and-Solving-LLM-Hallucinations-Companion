{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6: Continuous Improvement and Feedback Loops\n",
    "\n",
    "Continuous improvement is crucial for maintaining the relevance and accuracy of Large Language Models (LLMs). Feedback loops allow LLMs to adapt to user needs by integrating feedback and retraining periodically.\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this chapter, you will be able to:\n",
    "- Understand the importance of feedback loops in improving LLM performance.\n",
    "- Collect user feedback systematically.\n",
    "- Implement workflows for retraining models with new data.\n",
    "- Automate feedback integration into continuous improvement processes.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Importance of Continuous Improvement\n",
    "\n",
    "LLMs need to adapt to new information, changing user needs, and domain-specific requirements. Feedback loops provide a structured approach to:\n",
    "- Identify errors or shortcomings in model responses.\n",
    "- Collect and process new data for retraining.\n",
    "- Improve accuracy and relevance over time.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Collecting Feedback\n",
    "\n",
    "### Example: Logging User Feedback in a Chat Application\n",
    "\n",
    "In this example, we'll simulate a chatbot application that collects user feedback for each response.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated feedback collection\n",
    "feedback_log = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_feedback(response, feedback):\n",
    "    \"\"\"Collects user feedback on a model's response.\"\"\"\n",
    "    feedback_log.append({\"response\": response, \"feedback\": feedback})\n",
    "    return \"Feedback recorded.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "response = \"Mars is the fourth planet from the Sun.\"\n",
    "feedback = \"Correct, but lacks information about the atmosphere.\"\n",
    "print(collect_feedback(response, feedback))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the feedback log\n",
    "print(\"\\nFeedback Log:\")\n",
    "print(feedback_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Observations\n",
    "\n",
    "1. **Feedback Quality**: Ensure that feedback is specific and actionable. For example, \"Too vague\" can be replaced with \"Add details about Mars's atmosphere.\"\n",
    "2. **Feedback Volume**: Collect sufficient feedback for meaningful retraining. A single piece of feedback is not representative of user needs.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Retraining the Model with Feedback Data\n",
    "\n",
    "Retraining the model involves updating it with new data derived from user feedback. This process requires:\n",
    "1. **Preprocessing Feedback**: Converting feedback into a training dataset.\n",
    "2. **Updating the Model**: Fine-tuning the existing model with the feedback data.\n",
    "\n",
    "### Example: Converting Feedback into Training Data\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example feedback data\n",
    "feedback_data = [\n",
    "    {\"input\": \"Tell me about Mars.\", \"response\": \"Mars is the fourth planet.\", \"feedback\": \"Include details about its atmosphere.\"},\n",
    "    {\"input\": \"What is AI?\", \"response\": \"AI is automation.\", \"feedback\": \"Mention machine learning and deep learning.\"}\n",
    "]\n",
    "\n",
    "# Convert feedback data into a training dataset\n",
    "training_data = pd.DataFrame(feedback_data)\n",
    "training_data['target'] = training_data['response'] + \" \" + training_data['feedback']\n",
    "print(\"Training Data:\")\n",
    "print(training_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Fine-Tuning the Model with Feedback Data\n",
    "\n",
    "The processed feedback data can be used to fine-tune the model.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments, AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# Load a pre-trained model and tokenizer\n",
    "model_name = \"meta-llama/Llama-2-7b\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# Tokenise the training data\n",
    "inputs = tokenizer(list(training_data['input']), return_tensors=\"pt\", padding=True, truncation=True)\n",
    "outputs = tokenizer(list(training_data['target']), return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "# Create a dataset\n",
    "dataset = torch.utils.data.TensorDataset(inputs['input_ids'], outputs['input_ids'])\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./retrained_model\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=2\n",
    ")\n",
    "\n",
    "# Retrain the model\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=dataset)\n",
    "trainer.train()\n",
    "\n",
    "# Save the retrained model\n",
    "model.save_pretrained(\"./retrained_model\")\n",
    "print(\"\\nRetrained model saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Observations\n",
    "\n",
    "1. **Dataset Size**: Retraining requires sufficient data to avoid overfitting on a small dataset.\n",
    "2. **Model Updates**: Retraining should focus on specific areas of improvement to avoid degrading general performance.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Automating Feedback Loops\n",
    "\n",
    "### Example: Automating Feedback Collection and Model Updates\n",
    "\n",
    "We can integrate feedback collection and model updates into a continuous workflow using APIs or task schedulers.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Example: Automating feedback collection\n",
    "def save_feedback_to_file(feedback, file_path=\"feedback.json\"):\n",
    "    \"\"\"Save feedback to a file for batch processing.\"\"\"\n",
    "    with open(file_path, \"a\") as f:\n",
    "        json.dump(feedback, f)\n",
    "        f.write(\"\\n\")\n",
    "    print(\"Feedback saved.\")\n",
    "\n",
    "# Save feedback\n",
    "feedback = {\"input\": \"What is Python?\", \"response\": \"Python is a snake.\", \"feedback\": \"Mention that Python is a programming language.\"}\n",
    "save_feedback_to_file(feedback)\n",
    "\n",
    "# Example: Batch processing feedback for model updates\n",
    "def load_feedback_from_file(file_path=\"feedback.json\"):\n",
    "    \"\"\"Load feedback data from a file.\"\"\"\n",
    "    feedback_data = []\n",
    "    with open(file_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            feedback_data.append(json.loads(line))\n",
    "    return feedback_data\n",
    "\n",
    "# Load feedback for retraining\n",
    "batch_feedback = load_feedback_from_file()\n",
    "print(\"\\nLoaded Feedback Data:\")\n",
    "print(batch_feedback)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Observations\n",
    "\n",
    "1. **Automation Benefits**: Automating feedback collection saves time and ensures consistent updates.\n",
    "2. **Data Integrity**: Verify feedback data before using it for retraining to avoid introducing errors.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Key Takeaways\n",
    "\n",
    "- Feedback loops are essential for improving LLM accuracy and relevance.\n",
    "- Retraining with feedback data allows the model to adapt to user needs.\n",
    "- Automating feedback collection and processing streamlines continuous improvement.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Summary\n",
    "\n",
    "In this chapter, we explored continuous improvement techniques for LLMs:\n",
    "\n",
    "1. **Feedback Collection**: Logging and processing user feedback systematically.\n",
    "2. **Retraining**: Using feedback data to fine-tune the model for improved accuracy.\n",
    "3. **Automation**: Integrating feedback loops into workflows for seamless updates.\n",
    "\n",
    "These practices ensure that LLMs remain accurate and relevant, even as user needs evolve.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
