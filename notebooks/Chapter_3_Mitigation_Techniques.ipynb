{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3: Techniques for Mitigating Hallucinations in Large Language Models (LLMs)\n",
    "\n",
    "This chapter covers several techniques to reduce hallucinations in Large Language Models (LLMs). By implementing these methods, we can help models generate responses that are more accurate and grounded in factual information.\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this chapter, you will be able to:\n",
    "- Apply prompt engineering techniques to guide LLMs toward more accurate responses.\n",
    "- Implement retrieval-based grounding to provide factual context to LLM outputs.\n",
    "- Understand the benefits of fine-tuning models with domain-specific data to reduce hallucinations.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Prompt Engineering\n",
    "\n",
    "**Prompt engineering** involves crafting input prompts in a way that guides the model to produce more accurate responses. By making prompts clear and context-rich, we can reduce the likelihood of hallucination.\n",
    "\n",
    "### Example: Crafting Effective Prompts\n",
    "\n",
    "Let’s try an example of how slight changes in prompt wording can impact the model’s response.\n",
    "\n",
    "---\n",
    "\n",
    "### Code Implementation: Prompt Engineering\n",
    "\n",
    "In this example, we’ll compare two different prompts and observe how GPT-4 and LLaMA respond to each.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up OpenAI API for GPT-4\n",
    "openai.api_key = \"YOUR_OPENAI_API_KEY\"  # Replace with your OpenAI API key\n",
    "\n",
    "def gpt4_response(prompt):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response['choices'][0]['message']['content']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up LLaMA model\n",
    "llama_tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b\")\n",
    "llama_model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b\")\n",
    "\n",
    "def llama_response(prompt):\n",
    "    inputs = llama_tokenizer(prompt, return_tensors=\"pt\")\n",
    "    outputs = llama_model.generate(inputs[\"input_ids\"], max_length=50, num_return_sequences=1)\n",
    "    return llama_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define prompts\n",
    "basic_prompt = \"Describe Mars.\"\n",
    "detailed_prompt = \"Describe the planet Mars, including its atmosphere, surface features, and any recent exploration missions.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with GPT-4o\n",
    "print(\"GPT-4o Response to Basic Prompt:\")\n",
    "print(gpt4_response(basic_prompt))\n",
    "print(\"\\nGPT-4 Response to Detailed Prompt:\")\n",
    "print(gpt4_response(detailed_prompt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with LLaMA\n",
    "print(\"\\nLLaMA Response to Basic Prompt:\")\n",
    "print(llama_response(basic_prompt))\n",
    "print(\"\\nLLaMA Response to Detailed Prompt:\")\n",
    "print(llama_response(detailed_prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Observations\n",
    "\n",
    "After running the code above, compare the responses to each prompt:\n",
    "\n",
    "1. **Detail and Specificity**: Does the detailed prompt provide a more accurate and context-rich response?\n",
    "2. **Reduction in Hallucination**: Observe if the detailed prompt helps to reduce any fabricated information about Mars.\n",
    "3. **Differences Between Models**: Note if GPT-4 or LLaMA handles the prompt variations differently.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Retrieval-Based Grounding\n",
    "\n",
    "**Retrieval-based grounding** is a technique where we provide the model with specific, factual information before generating a response. This approach is useful for reducing hallucination by grounding the model’s response in external data.\n",
    "\n",
    "### Example: Implementing Retrieval-Based Grounding\n",
    "\n",
    "In this example, we’ll simulate retrieval-based grounding by using a basic knowledge base and retrieving relevant information to provide context.\n",
    "\n",
    "---\n",
    "\n",
    "### Code Implementation: Retrieval-Based Grounding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated knowledge base with factual information\n",
    "knowledge_base = {\n",
    "    \"Mars\": \"Mars is the fourth planet from the Sun. It has a thin atmosphere composed mostly of carbon dioxide.\",\n",
    "    \"solar system\": \"The Solar System consists of the Sun and the celestial bodies that orbit it, including planets, moons, and asteroids.\",\n",
    "    \"NASA\": \"NASA is the United States' space agency, responsible for the nation’s civilian space program and for aeronautics and aerospace research.\"\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grounded_response(query):\n",
    "    # Search for relevant information in the knowledge base\n",
    "    for key, info in knowledge_base.items():\n",
    "        if key.lower() in query.lower():\n",
    "            return f\"{info}\\n\\nAdditional response: The model can add context based on this factual grounding.\"\n",
    "    return \"No relevant information found in the knowledge base.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example queries\n",
    "query_1 = \"Tell me about Mars.\"\n",
    "query_2 = \"What is NASA's role in space exploration?\"\n",
    "\n",
    "# Generate grounded responses\n",
    "print(\"Grounded Response for Query 1:\")\n",
    "print(grounded_response(query_1))\n",
    "print(\"\\nGrounded Response for Query 2:\")\n",
    "print(grounded_response(query_2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise: Building a Basic Knowledge Base\n",
    "\n",
    "### Instructions\n",
    "\n",
    "1. **Expand the Knowledge Base**: Add more entries to `knowledge_base` with factual information about topics like \"Jupiter,\" \"Milky Way,\" or \"Apollo missions.\"\n",
    "2. **Test with Additional Queries**: Run the `grounded_response` function with new queries to see how well it retrieves relevant information and grounds the model’s responses.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Fine-Tuning the Model\n",
    "\n",
    "Fine-tuning an LLM with domain-specific data is another powerful technique to reduce hallucinations. When a model is fine-tuned on targeted, high-quality data, it becomes more specialised in that domain and is less likely to produce incorrect information.\n",
    "\n",
    "### Example: Explanation of Fine-Tuning Process\n",
    "\n",
    "To fine-tune a model, we need a dataset that’s representative of the target domain. We then train the model further on this data with lower learning rates and fewer epochs than initial training. This helps it adapt to new information without overfitting.\n",
    "\n",
    "> **Note**: For this notebook, we won’t perform fine-tuning directly due to resource constraints, but you can refer to the code template below as a guide.\n",
    "\n",
    "---\n",
    "\n",
    "### Code Template for Fine-Tuning with Transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments, AutoModelForCausalLM, AutoTokenizer\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset\n",
    "# Assuming `dataset.csv` contains columns 'input_text' and 'target_text' for fine-tuning\n",
    "data = pd.read_csv(\"path/to/your/dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b\")\n",
    "inputs = tokenizer(list(data['input_text']), return_tensors=\"pt\", padding=True, truncation=True)\n",
    "outputs = tokenizer(list(data['target_text']), return_tensors=\"pt\", padding=True, truncation=True)\n",
    "dataset = torch.utils.data.TensorDataset(inputs[\"input_ids\"], outputs[\"input_ids\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning setup\n",
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b\")\n",
    "training_args = TrainingArguments(output_dir=\"./results\", num_train_epochs=3, per_device_train_batch_size=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=dataset)\n",
    "trainer.train()\n",
    "\n",
    "# Save fine-tuned model\n",
    "model.save_pretrained(\"./fine_tuned_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this chapter, we covered several techniques to mitigate hallucinations in LLMs:\n",
    "\n",
    "1. **Prompt Engineering**: Crafting prompts carefully to guide model responses.\n",
    "2. **Retrieval-Based Grounding**: Providing factual context to help ground the model’s output.\n",
    "3. **Fine-Tuning**: Training the model further on specific data to reduce hallucinations in that domain.\n",
    "\n",
    "Using these techniques can significantly improve the accuracy and reliability of LLM responses, making them more suitable for applications where factual correctness is critical.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
